#!/usr/bin/env python3
"""
Start the Enhanced LinkedIn Sourcing Agent FastAPI server with Groq/Llama integration
"""

import uvicorn
import sys
import os

# Add the current directory to Python path
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

if __name__ == "__main__":
    print("ğŸš€ Starting Enhanced LinkedIn Sourcing Agent API Server...")
    print("ğŸ¤– Powered by Groq API + Llama models")
    print("ğŸ“¡ API will be available at: http://localhost:8000")
    print("ğŸŒ Frontend will be available at: http://localhost:8000/frontend")
    print("ğŸ“š API documentation at: http://localhost:8000/docs")
    print("ğŸ’š Health check at: http://localhost:8000/health")
    print("\nPress Ctrl+C to stop the server")
    
    try:
        uvicorn.run(
            "backend.enhanced_main:app",
            host="0.0.0.0",
            port=8000,
            reload=True,
            log_level="info"
        )
    except KeyboardInterrupt:
        print("\nğŸ‘‹ Server stopped by user")
    except Exception as e:
        print(f"âŒ Error starting server: {e}")
        sys.exit(1) 